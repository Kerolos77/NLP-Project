# NLP-Project

>Arabic Text Summarization Approach based on Transformers

Abstract :
Transfer learning with a unified Transformer frame-work (T5) that converts all language problems intoa text-to-text format has recently been proposedas  a  simple,  yet  effective,  transfer  learning  ap-proach.   Although a multilingual version of theT5  model  (mT5)  has  been  introduced,  it  is  notclear how well it can fare on non-English tasksinvolving diverse data.  To investigate this ques-tion, we apply mT5 on a language with a wide va-riety of dialectsâ€“Arabic.

Introduction:
Due to their remarkable ability to transfer knowl-edge from unlabeled data to downstream tasks, pre-trained Transformer-based language models haveemerged as important components in modern natu-ral language processing (NLP) systems. In partic-ular, the unified framework that converts all text-based language problems into a text-to-text formatpresented through the T5 model is attractive.

Data Provided :
If you want to train your model ,you can use this dataset and download 
MSA Data.We   use70GB   of   MSA   text(7.1B   tokens)   

Provided Models :
Arabic T5 Model 
https://huggingface.co/marefa-nlp/summarization-arabic-english-news
